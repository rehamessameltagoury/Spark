{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MrBC530gmg5"
   },
   "source": [
    "Let's start with your project: \n",
    "\n",
    "Are you a data scientist? \n",
    "\n",
    "I think you are an awesome a data scientist.\n",
    "\n",
    "### **Problem** \n",
    "**Our goal is to create a predictive model that can answer the following question:**\n",
    "\n",
    "**What kind of people had a better chance of surviving?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhBfwzBgioTD"
   },
   "source": [
    "**Data about passengers:**\n",
    "*   Name\n",
    "*   Age\n",
    "*   Gender.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIEH8iZqi-sk"
   },
   "source": [
    "## Install and Import Libraries\n",
    "Let's install PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oj1HhvIOY5Yz"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDp80mG9jmfU"
   },
   "source": [
    "## Build Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ttzML9fpjE5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/06 02:30:37 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.130.131 instead (on interface ens33)\n",
      "21/10/06 02:30:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/10/06 02:30:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sp = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('practicallab').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiqECDzLj1Mg"
   },
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn-hxNggkTqV"
   },
   "source": [
    "You have two datasets: \n",
    "* Train  \n",
    "* Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8-A8M7QmKDJ"
   },
   "source": [
    "Read two datasets: \n",
    "* Train\n",
    "* Test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Mx2qAccBk15y"
   },
   "outputs": [],
   "source": [
    "train = spark.read.csv('train.csv', header=True, inferSchema=True)\n",
    "test = spark.read.csv('test.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.show()\n",
    "# test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj2ANTnWmSCq"
   },
   "source": [
    "Let's work with train dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5mWJR30lNs5"
   },
   "source": [
    "**Confirm if this is a dataframe or not:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tEYTePrzk9yl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvLJElPrlT4i"
   },
   "source": [
    "**Show 5 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jYwhqvV8lnO0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QIYVxRXlnnw"
   },
   "source": [
    "**Display schema for the dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pcvERiICl1Ep"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmE3Wd80l1S6"
   },
   "source": [
    "**Statistical summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cNY0SItol5Mo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "summary=train.describe()\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiFaIEQTl70_"
   },
   "source": [
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSNPOnP8mw2Q"
   },
   "source": [
    "**Display count for the train dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zrtpG11Fl9HM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_6nnTfxm9_x"
   },
   "source": [
    "**Can you answer this question:** \n",
    "\n",
    "**How many people survived, and how many didn't survive?** \n",
    "\n",
    "**Please save data in a variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QDoqPwyomYxA"
   },
   "outputs": [],
   "source": [
    "survived=train.select('Survived').where(train.Survived==1).count()\n",
    "not_survived=train.count()-survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8DUtZXPn46m"
   },
   "source": [
    "**Display your result:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0XHAK8ceoCMU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived: 342 , Didn't Survive: 549\n"
     ]
    }
   ],
   "source": [
    "print(\"Survived: {} , Didn't Survive: {}\".format(survived,not_survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ygsg7wQqor9a"
   },
   "source": [
    "**Can you display your answer in ratio form?(Hint: Use UDF.)**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3uiaN29PoQnf"
   },
   "outputs": [],
   "source": [
    "def ratio(survived,notsurv):\n",
    "    sur_ratio=survived/(survived+notsurv)\n",
    "    not_sur_ration=notsurv/(survived+notsurv)\n",
    "    return sur_ratio*100,not_sur_ration*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PvzEwesgoQ3s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of Survived: 38.38383838383838 % , Ratio of didn't survive: 61.61616161616161 % \n"
     ]
    }
   ],
   "source": [
    "survived,not_survived=ratio(survived,not_survived)\n",
    "print(\"Ratio of Survived: {} % , Ratio of didn't survive: {} % \".format(survived,not_survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7Aker_lp1h4"
   },
   "source": [
    "**Can you get the number of males and females?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XllkDlo3ongJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male: 577 , Female: 314\n"
     ]
    }
   ],
   "source": [
    "male=train.select('Sex').where(train.Sex=='male').count()\n",
    "female=train.select('Sex').where(train.Sex=='female').count()\n",
    "print(\"Male: {} , Female: {}\".format(male,female))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHFaJ15zqtEV"
   },
   "source": [
    "**1. What is the average number of survivors of each gender?**\n",
    "\n",
    "**2. What is the number of survivors of each gender?**\n",
    "\n",
    "(Hint: Group by the \"sex\" column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male Survived: 109, Female Survived: 233\n"
     ]
    }
   ],
   "source": [
    "male_surv=train.select('Sex').where((train.Sex=='male') & (train.Survived==1)).count()\n",
    "female_surv=train.select('Sex').where((train.Sex=='female') & (train.Survived==1)).count()\n",
    "print(\"Male Survived: {}, Female Survived: {}\".format(male_surv,female_surv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NUikH7MUqdKq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the average number of survivors of each gender?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 28:============================================>          (80 + 2) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|   Sex|      avg(Survived)|\n",
      "+------+-------------------+\n",
      "|female| 0.7420382165605095|\n",
      "|  male|0.18890814558058924|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 30:===============================================>        (64 + 2) / 75]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"What is the average number of survivors of each gender?\")\n",
    "train.groupBy('Sex').agg({'Survived':'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCEdYNdArtRN"
   },
   "source": [
    "**Create temporary view PySpark:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YjlK6HDUqsI5"
   },
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView(\"train_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXNePifnshHr"
   },
   "source": [
    "**How many people survived, and how many didn't survive? By SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0HxfPRTMslqk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Survived|\n",
      "+--------+\n",
      "|     342|\n",
      "+--------+\n",
      "\n",
      "+------------+\n",
      "|Not_survived|\n",
      "+------------+\n",
      "|         549|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select count(Survived) as Survived from train_tbl where Survived ==1\"\"\").show()\n",
    "spark.sql(\"\"\"select count(Survived) as Not_survived from train_tbl where Survived !=1\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVCdY6EasFWV"
   },
   "source": [
    "**Can you display the number of survivors from each gender as a ratio?**\n",
    "\n",
    "(Hint: Group by \"sex\" column.)\n",
    "\n",
    "**Can you do this via SQL?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7xQc3pUUr3HF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 42:======================================================>(99 + 1) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|   Sex|     Survived_Ratio|\n",
      "+------+-------------------+\n",
      "|female| 0.7420382165605095|\n",
      "|  male|0.18890814558058924|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select Sex,avg(Survived)as Survived_Ratio From train_tbl group by Sex').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6QXc5V8uu3Y"
   },
   "source": [
    "**Display a ratio for p-class:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Mscs2mDFdFsD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/06 02:31:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 46:====================================>                 (136 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|Pclass|Pclass_Ratio       |\n",
      "+------+-------------------+\n",
      "|1     |0.24242424242424243|\n",
      "|3     |0.5510662177328844 |\n",
      "|2     |0.20650953984287318|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:=====================================================>(199 + 1) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Pclass, \\\n",
    "count(Pclass)/ sum(count(*)) over () as Pclass_Ratio \\\n",
    "          From train_tbl  group by Pclass\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX0klxwAvg6J"
   },
   "source": [
    "**Let's take a break and continue after this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ctM9t8atxJl"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CfanZTCt6Wk"
   },
   "source": [
    "**First and foremost, we must merge both the train and test datasets. (Hint: The union function can do this.)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8Nm8S1K0r4uY"
   },
   "outputs": [],
   "source": [
    "test.createOrReplaceTempView(\"test_tbl\")\n",
    "df=spark.sql(\"\"\"select * from train_tbl union select * from test_tbl\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI7AD8FLz3iO"
   },
   "source": [
    "**Display count:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "I4rd9e6nzzr5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVQlr9vDy7Y4"
   },
   "source": [
    "**Temporary view PySpark:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "s_WERAL8wvJa"
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R4Miuy0z_uP"
   },
   "source": [
    "**Can you define the number of null values in each column?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "0LMOalKBxhpD"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "def null_value_count(df):\n",
    "    nullColumnsCounts = []\n",
    "    Rows = df.count()\n",
    "    for k in df.columns:\n",
    "        Rows = df.where(col(k).isNull()).count()\n",
    "        if(Rows > 0):\n",
    "            temp = k,Rows\n",
    "            nullColumnsCounts.append(temp)\n",
    "    return(nullColumnsCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "null_columns_count_list = null_value_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Age', 265), ('Cabin', 1021), ('Embarked', 3)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_columns_count_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBX8cJ000aqe"
   },
   "source": [
    "**Create Dataframe for null values**\n",
    "\n",
    "1. Column\n",
    "2. Number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ITmyUelNxjJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+\n",
      "| Age|Embarked|Cabin|\n",
      "+----+--------+-----+\n",
      "|39.0|       S| null|\n",
      "| 9.0|       S| null|\n",
      "|40.0|       S|  B94|\n",
      "|36.0|       C|    D|\n",
      "|26.0|       S| null|\n",
      "|null|       C| null|\n",
      "|null|       S| C124|\n",
      "|48.0|       S| null|\n",
      "|22.0|       S| null|\n",
      "|38.0|       S| null|\n",
      "|45.0|       S| null|\n",
      "|36.0|       S|  E25|\n",
      "|60.0|       S| null|\n",
      "|null|       S| null|\n",
      "|30.0|       S| null|\n",
      "|null|       S| null|\n",
      "|22.0|       S| null|\n",
      "|null|       Q| null|\n",
      "|29.0|       S|   B5|\n",
      "| 2.0|       Q| null|\n",
      "+----+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_null=df.select(df.Age,df.Embarked,df.Cabin)\n",
    "df_null.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuKrOi5a0-Ma"
   },
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txa8NZIO1JaP"
   },
   "source": [
    "**Can you show me the name column from your temporary table?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "m7yXqJoJy35k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Name|\n",
      "+--------------------+\n",
      "|Andersson, Mr. An...|\n",
      "|\"Goldsmith, Maste...|\n",
      "|Harrison, Mr. Wil...|\n",
      "|Levy, Mr. Rene Ja...|\n",
      "|Nilsson, Miss. He...|\n",
      "|   Yousif, Mr. Wazli|\n",
      "|  Klaber, Mr. Herman|\n",
      "|Herman, Mrs. Samu...|\n",
      "|Dahlberg, Miss. G...|\n",
      "|Asplund, Mrs. Car...|\n",
      "|\"Romaine, Mr. Cha...|\n",
      "|\"Flynn, Mr. John ...|\n",
      "|Brown, Mr. Thomas...|\n",
      "|        Lam, Mr. Ali|\n",
      "|Somerton, Mr. Fra...|\n",
      "|Risien, Mr. Samue...|\n",
      "|  Ohman, Miss. Velin|\n",
      "|\"O'Leary, Miss. H...|\n",
      "|Allen, Miss. Elis...|\n",
      "|Rice, Master. Eugene|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select Name from df_tbl').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F0F9cTZ2Cuz"
   },
   "source": [
    "**Run this code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0kx6OcB-2BBT"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "combined = df.withColumn('Title',F.regexp_extract(F.col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "combined.createOrReplaceTempView('combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbZeUWS12r59"
   },
   "source": [
    "**Display the title and count \"Title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "hGkFMtlp1FAI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| Title|\n",
      "+------+\n",
      "|    Mr|\n",
      "|Master|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|  Miss|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|   Mrs|\n",
      "|  Miss|\n",
      "|   Mrs|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|  Miss|\n",
      "|  Miss|\n",
      "|  Miss|\n",
      "|Master|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined.select(combined.Title).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 103:==========================================>          (161 + 2) / 200]\r",
      "\r",
      "[Stage 103:=============================================>       (172 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|count(Title)|\n",
      "+------------+\n",
      "|        1329|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 103:================================================>    (184 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(Title) from combined\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLBQDKYu4JOa"
   },
   "source": [
    "**We can see that Dr, Rev, Major, Col, Mlle, Capt, Don, Jonkheer, Countess, Ms, Sir, Lady, and Mme are really rare titles, so create Dictionary and set the value to \"rare\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "rjnx5l5r2Qaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Dr': 'rare',\n",
       " 'Rev': 'rare',\n",
       " 'Major': 'rare',\n",
       " 'Col': 'rare',\n",
       " 'Mlle': 'rare',\n",
       " 'Capt': 'rare',\n",
       " 'Don': 'rare',\n",
       " 'Jonkheer': 'rare',\n",
       " 'Countess': 'rare',\n",
       " 'Ms': 'rare',\n",
       " 'Sir': 'rare',\n",
       " 'Lady': 'rare',\n",
       " 'Mme': 'rare',\n",
       " 'Mr': 'Mr',\n",
       " 'Mrs': 'Mrs',\n",
       " 'Miss': 'Miss',\n",
       " 'Master': 'Master'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping={'Dr':'rare','Rev':'rare','Major':'rare','Col':'rare','Mlle':'rare','Capt':'rare',\n",
    "        'Don':'rare','Jonkheer':'rare','Countess':'rare','Ms':'rare','Sir':'rare','Lady':'rare','Mme':'rare','Mr':'Mr'\n",
    "        ,'Mrs':'Mrs','Miss':'Miss','Master':'Master'}\n",
    "for i in combined.select('Title').collect():\n",
    "    if i[0] not in mapping.keys():\n",
    "        mapping[i[0]]=i[0]\n",
    "mapping\n",
    "# combined = combined.replace(to_replace=mapping, subset=['Title'])\n",
    "# combined.select(combined.Title).show(50)\n",
    "# df2.select(df2.Title).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wrE95Cv7Oqh"
   },
   "source": [
    "**Run the function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "HdDbWuDl7Pf4"
   },
   "outputs": [],
   "source": [
    "\n",
    "def impute_title(title):\n",
    "    return mapping[title]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5EQVIhK7a9R"
   },
   "source": [
    "**Apply the function on \"Title\" column using UDF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "rBAiIOn77XFa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 108:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------------------------------------------------------+------+----+-----+-----+-------------+--------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|Name                                                     |Sex   |Age |SibSp|Parch|Ticket       |Fare    |Cabin|Embarked|Title |\n",
      "+-----------+--------+------+---------------------------------------------------------+------+----+-----+-----+-------------+--------+-----+--------+------+\n",
      "|14         |0       |3     |Andersson, Mr. Anders Johan                              |male  |39.0|1    |5    |347082       |31.275  |null |S       |Mr    |\n",
      "|166        |1       |3     |\"Goldsmith, Master. Frank John William \"\"Frankie\"\"\"      |male  |9.0 |0    |2    |363291       |20.525  |null |S       |Master|\n",
      "|264        |0       |1     |Harrison, Mr. William                                    |male  |40.0|0    |0    |112059       |0.0     |B94  |S       |Mr    |\n",
      "|293        |0       |2     |Levy, Mr. Rene Jacques                                   |male  |36.0|0    |0    |SC/Paris 2163|12.875  |D    |C       |Mr    |\n",
      "|316        |1       |3     |Nilsson, Miss. Helmina Josefina                          |female|26.0|0    |0    |347470       |7.8542  |null |S       |Miss  |\n",
      "|355        |0       |3     |Yousif, Mr. Wazli                                        |male  |null|0    |0    |2647         |7.225   |null |C       |Mr    |\n",
      "|712        |0       |1     |Klaber, Mr. Herman                                       |male  |null|0    |0    |113028       |26.55   |C124 |S       |Mr    |\n",
      "|755        |1       |2     |Herman, Mrs. Samuel (Jane Laver)                         |female|48.0|1    |2    |220845       |65.0    |null |S       |Mrs   |\n",
      "|883        |0       |3     |Dahlberg, Miss. Gerda Ulrika                             |female|22.0|0    |0    |7552         |10.5167 |null |S       |Miss  |\n",
      "|26         |1       |3     |Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson)|female|38.0|1    |5    |347077       |31.3875 |null |S       |Mrs   |\n",
      "|188        |1       |1     |\"Romaine, Mr. Charles Hallace (\"\"Mr C Rolmane\"\")\"        |male  |45.0|0    |0    |111428       |26.55   |null |S       |Mr    |\n",
      "|573        |1       |1     |\"Flynn, Mr. John Irwin (\"\"Irving\"\")\"                     |male  |36.0|0    |0    |PC 17474     |26.3875 |E25  |S       |Mr    |\n",
      "|685        |0       |2     |Brown, Mr. Thomas William Solomon                        |male  |60.0|1    |1    |29750        |39.0    |null |S       |Mr    |\n",
      "|693        |1       |3     |Lam, Mr. Ali                                             |male  |null|0    |0    |1601         |56.4958 |null |S       |Mr    |\n",
      "|36         |0       |3     |Somerton, Mr. Francis William                            |male  |30.0|0    |0    |A.5. 18509   |8.05    |null |S       |Mr    |\n",
      "|86         |0       |3     |Risien, Mr. Samuel Beard                                 |male  |null|0    |0    |364498       |14.5    |null |S       |Mr    |\n",
      "|102        |1       |3     |Ohman, Miss. Velin                                       |female|22.0|0    |0    |347085       |7.775   |null |S       |Miss  |\n",
      "|201        |1       |3     |\"O'Leary, Miss. Hanora \"\"Norah\"\"\"                        |female|null|0    |0    |330919       |7.8292  |null |Q       |Miss  |\n",
      "|278        |1       |1     |Allen, Miss. Elisabeth Walton                            |female|29.0|0    |0    |24160        |211.3375|B5   |S       |Miss  |\n",
      "|17         |0       |3     |Rice, Master. Eugene                                     |male  |2.0 |4    |1    |382652       |29.125  |null |Q       |Master|\n",
      "+-----------+--------+------+---------------------------------------------------------+------+----+-----+-----+-------------+--------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "impute_title_udf=udf(lambda title:impute_title(title))\n",
    "\n",
    "combined.withColumn(\"Title\", impute_title_udf(F.col(\"Title\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn8ewllf7kiV"
   },
   "source": [
    "**Display \"Title\" from table and group by \"Title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "J9sjQb084GU6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| Title|\n",
      "+------+\n",
      "|    Mr|\n",
      "|Master|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|  Miss|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|   Mrs|\n",
      "|  Miss|\n",
      "|   Mrs|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|  Miss|\n",
      "|  Miss|\n",
      "|  Miss|\n",
      "|Master|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined.select(combined.Title).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H45QNLj9vJp"
   },
   "source": [
    "## **Preprocessing Age**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwRAhumK-u__"
   },
   "source": [
    "**Based on the age mean, you will fill in the missing age values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "eXYSVzvl4z63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.079501879699244"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "mean = combined.select(mean(combined['Age'])).collect()\n",
    "mean[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLPivde8_GI-"
   },
   "source": [
    "**Fill missing age with age mean:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "lBgW8aFD90PA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|               Age|\n",
      "+------------------+\n",
      "|              39.0|\n",
      "|               9.0|\n",
      "|              40.0|\n",
      "|              36.0|\n",
      "|              26.0|\n",
      "|30.079501879699244|\n",
      "|30.079501879699244|\n",
      "|              48.0|\n",
      "|              22.0|\n",
      "|              38.0|\n",
      "|              45.0|\n",
      "|              36.0|\n",
      "|              60.0|\n",
      "|30.079501879699244|\n",
      "|              30.0|\n",
      "|30.079501879699244|\n",
      "|              22.0|\n",
      "|30.079501879699244|\n",
      "|              29.0|\n",
      "|               2.0|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined = combined.na.fill(mean[0][0], subset='Age')\n",
    "combined.select('Age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGsnUz-m_P95"
   },
   "source": [
    "## **Preprocessing Embarked**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHbbamcXMSYP"
   },
   "source": [
    "**Select Embarked, count them, order by count Desc, and save in grouped_Embarked variable:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "v-lRu5vc_FW7"
   },
   "outputs": [],
   "source": [
    "\n",
    "embarked = combined.select('Embarked')\\\n",
    "                            .groupBy('Embarked')\\\n",
    "                            .count().orderBy('count',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1qf5u2IOQrx"
   },
   "source": [
    "**Show groupped_Embarked:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "jSFNDTNg_erb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:==========================================>          (162 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       S|  962|\n",
      "|       C|  253|\n",
      "|       Q|  111|\n",
      "|    null|    3|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "embarked.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzQWYgKBMrbp"
   },
   "source": [
    "**Get the groupped_Embarked:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "uu46QWrn_gCX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Embarked='S', count=962),\n",
       " Row(Embarked='C', count=253),\n",
       " Row(Embarked='Q', count=111),\n",
       " Row(Embarked=None, count=3)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8vhoEs8N2w_"
   },
   "source": [
    "**Fill missing values with Top 'S' of grouped_Embarked:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "LdzQCRud_mAa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------------+--------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|       Ticket|    Fare|Cabin|Embarked| Title|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------------+--------+-----+--------+------+\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|       347082|  31.275| null|       S|    Mr|\n",
      "|        166|       1|     3|\"Goldsmith, Maste...|  male|               9.0|    0|    2|       363291|  20.525| null|       S|Master|\n",
      "|        264|       0|     1|Harrison, Mr. Wil...|  male|              40.0|    0|    0|       112059|     0.0|  B94|       S|    Mr|\n",
      "|        293|       0|     2|Levy, Mr. Rene Ja...|  male|              36.0|    0|    0|SC/Paris 2163|  12.875|    D|       C|    Mr|\n",
      "|        316|       1|     3|Nilsson, Miss. He...|female|              26.0|    0|    0|       347470|  7.8542| null|       S|  Miss|\n",
      "|        355|       0|     3|   Yousif, Mr. Wazli|  male|30.079501879699244|    0|    0|         2647|   7.225| null|       C|    Mr|\n",
      "|        712|       0|     1|  Klaber, Mr. Herman|  male|30.079501879699244|    0|    0|       113028|   26.55| C124|       S|    Mr|\n",
      "|        755|       1|     2|Herman, Mrs. Samu...|female|              48.0|    1|    2|       220845|    65.0| null|       S|   Mrs|\n",
      "|        883|       0|     3|Dahlberg, Miss. G...|female|              22.0|    0|    0|         7552| 10.5167| null|       S|  Miss|\n",
      "|         26|       1|     3|Asplund, Mrs. Car...|female|              38.0|    1|    5|       347077| 31.3875| null|       S|   Mrs|\n",
      "|        188|       1|     1|\"Romaine, Mr. Cha...|  male|              45.0|    0|    0|       111428|   26.55| null|       S|    Mr|\n",
      "|        573|       1|     1|\"Flynn, Mr. John ...|  male|              36.0|    0|    0|     PC 17474| 26.3875|  E25|       S|    Mr|\n",
      "|        685|       0|     2|Brown, Mr. Thomas...|  male|              60.0|    1|    1|        29750|    39.0| null|       S|    Mr|\n",
      "|        693|       1|     3|        Lam, Mr. Ali|  male|30.079501879699244|    0|    0|         1601| 56.4958| null|       S|    Mr|\n",
      "|         36|       0|     3|Somerton, Mr. Fra...|  male|              30.0|    0|    0|   A.5. 18509|    8.05| null|       S|    Mr|\n",
      "|         86|       0|     3|Risien, Mr. Samue...|  male|30.079501879699244|    0|    0|       364498|    14.5| null|       S|    Mr|\n",
      "|        102|       1|     3|  Ohman, Miss. Velin|female|              22.0|    0|    0|       347085|   7.775| null|       S|  Miss|\n",
      "|        201|       1|     3|\"O'Leary, Miss. H...|female|30.079501879699244|    0|    0|       330919|  7.8292| null|       Q|  Miss|\n",
      "|        278|       1|     1|Allen, Miss. Elis...|female|              29.0|    0|    0|        24160|211.3375|   B5|       S|  Miss|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|       382652|  29.125| null|       Q|Master|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------------+--------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined.na.fill('S',subset='Embarked').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------------+--------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|       Ticket|    Fare|Cabin|Embarked| Title|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------------+--------+-----+--------+------+\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|       347082|  31.275| null|       S|    Mr|\n",
      "|        166|       1|     3|\"Goldsmith, Maste...|  male|               9.0|    0|    2|       363291|  20.525| null|       S|Master|\n",
      "|        264|       0|     1|Harrison, Mr. Wil...|  male|              40.0|    0|    0|       112059|     0.0|  B94|       S|    Mr|\n",
      "|        293|       0|     2|Levy, Mr. Rene Ja...|  male|              36.0|    0|    0|SC/Paris 2163|  12.875|    D|       C|    Mr|\n",
      "|        316|       1|     3|Nilsson, Miss. He...|female|              26.0|    0|    0|       347470|  7.8542| null|       S|  Miss|\n",
      "|        355|       0|     3|   Yousif, Mr. Wazli|  male|30.079501879699244|    0|    0|         2647|   7.225| null|       C|    Mr|\n",
      "|        712|       0|     1|  Klaber, Mr. Herman|  male|30.079501879699244|    0|    0|       113028|   26.55| C124|       S|    Mr|\n",
      "|        755|       1|     2|Herman, Mrs. Samu...|female|              48.0|    1|    2|       220845|    65.0| null|       S|   Mrs|\n",
      "|        883|       0|     3|Dahlberg, Miss. G...|female|              22.0|    0|    0|         7552| 10.5167| null|       S|  Miss|\n",
      "|         26|       1|     3|Asplund, Mrs. Car...|female|              38.0|    1|    5|       347077| 31.3875| null|       S|   Mrs|\n",
      "|        188|       1|     1|\"Romaine, Mr. Cha...|  male|              45.0|    0|    0|       111428|   26.55| null|       S|    Mr|\n",
      "|        573|       1|     1|\"Flynn, Mr. John ...|  male|              36.0|    0|    0|     PC 17474| 26.3875|  E25|       S|    Mr|\n",
      "|        685|       0|     2|Brown, Mr. Thomas...|  male|              60.0|    1|    1|        29750|    39.0| null|       S|    Mr|\n",
      "|        693|       1|     3|        Lam, Mr. Ali|  male|30.079501879699244|    0|    0|         1601| 56.4958| null|       S|    Mr|\n",
      "|         36|       0|     3|Somerton, Mr. Fra...|  male|              30.0|    0|    0|   A.5. 18509|    8.05| null|       S|    Mr|\n",
      "|         86|       0|     3|Risien, Mr. Samue...|  male|30.079501879699244|    0|    0|       364498|    14.5| null|       S|    Mr|\n",
      "|        102|       1|     3|  Ohman, Miss. Velin|female|              22.0|    0|    0|       347085|   7.775| null|       S|  Miss|\n",
      "|        201|       1|     3|\"O'Leary, Miss. H...|female|30.079501879699244|    0|    0|       330919|  7.8292| null|       Q|  Miss|\n",
      "|        278|       1|     1|Allen, Miss. Elis...|female|              29.0|    0|    0|        24160|211.3375|   B5|       S|  Miss|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|       382652|  29.125| null|       Q|Master|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------------+--------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEcdV5Vb_qR_"
   },
   "source": [
    "## **Preprocessing Cabin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BQzPs7tqhpA"
   },
   "source": [
    "**Replace \"cabin\" column with first char from the string:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "4b6L5pK0_nQz"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "combined=combined.withColumn('Cabin',split(col('Cabin'),\"\").getItem(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6H8XshnYj4k2"
   },
   "source": [
    "**Show the result:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "gJUQwnG1Oj2U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Cabin|\n",
      "+-----+\n",
      "| null|\n",
      "| null|\n",
      "|    B|\n",
      "|    D|\n",
      "| null|\n",
      "| null|\n",
      "|    C|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "|    E|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "|    B|\n",
      "| null|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined.select(combined.Cabin).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzSDsWsUj9Im"
   },
   "source": [
    "**Create the temporary view:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "MR7CXTY7_tMJ"
   },
   "outputs": [],
   "source": [
    "combined.createOrReplaceTempView(\"com_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv7lfQFkrLlN"
   },
   "source": [
    "**Select \"Cabin\" column, count Cabin column, Group by \"Cabin\" column, Order By count DESC**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "A0tZG_mvrKXv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 146:===================================================> (193 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Cabin|count|\n",
      "+-----+-----+\n",
      "|    C|   82|\n",
      "|    B|   77|\n",
      "|    D|   52|\n",
      "|    E|   51|\n",
      "|    A|   23|\n",
      "|    F|   18|\n",
      "|    G|    4|\n",
      "|    T|    1|\n",
      "| null|    0|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('select Cabin,count(Cabin) as count from com_tbl group by Cabin order by count(Cabin) Desc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GR6j0LOsB4y"
   },
   "source": [
    "**Fill missing values with \"U\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "mwq5CHEz_up_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Cabin|\n",
      "+-----+\n",
      "|    U|\n",
      "|    U|\n",
      "|    B|\n",
      "|    D|\n",
      "|    U|\n",
      "|    U|\n",
      "|    C|\n",
      "|    U|\n",
      "|    U|\n",
      "|    U|\n",
      "|    U|\n",
      "|    E|\n",
      "|    U|\n",
      "|    U|\n",
      "|    U|\n",
      "|    U|\n",
      "|    U|\n",
      "|    U|\n",
      "|    B|\n",
      "|    U|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined = combined.na.fill('U',subset='Cabin')\n",
    "combined.select(combined.Cabin).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRnhA_5-0Hi4"
   },
   "source": [
    "**StringIndexer: A label indexer that maps a string column of labels to an ML column of label indices. If the input column is numeric, we cast it to string and index the string values. The indices are in [0, numLabels). By default, this is ordered by label frequencies so the most frequent label gets index 0. The ordering behavior is controlled by setting stringOrderType. Its default value is frequencyDesc.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RIKlOX71GQ-"
   },
   "source": [
    "**StringIndexer(inputCol=None, outputCol=None)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0c_Hf_b0R12"
   },
   "source": [
    "**Pipeline: ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWfXaZ0I4dXD"
   },
   "source": [
    "____________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzFCa54R15-g"
   },
   "source": [
    "**Use Pipline to fit and transform:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "FXhtC8jH_xHE"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import numpy\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FsiLsd9452v"
   },
   "source": [
    "**VectorAssembler: VectorAssembler(*, inputCols=None, outputCol=None) A feature transformer that merges multiple columns into a vector column.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dU8DeZfh7JIo"
   },
   "source": [
    "**Use randomSplit function and split data to x_train, and X_test with 80% and 20% Consecutive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------------+--------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|       Ticket|    Fare|Cabin|Embarked| Title|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------------+--------+-----+--------+------+\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|              39.0|    1|    5|       347082|  31.275|    U|       S|    Mr|\n",
      "|        166|       1|     3|\"Goldsmith, Maste...|  male|               9.0|    0|    2|       363291|  20.525|    U|       S|Master|\n",
      "|        264|       0|     1|Harrison, Mr. Wil...|  male|              40.0|    0|    0|       112059|     0.0|    B|       S|    Mr|\n",
      "|        293|       0|     2|Levy, Mr. Rene Ja...|  male|              36.0|    0|    0|SC/Paris 2163|  12.875|    D|       C|    Mr|\n",
      "|        316|       1|     3|Nilsson, Miss. He...|female|              26.0|    0|    0|       347470|  7.8542|    U|       S|  Miss|\n",
      "|        355|       0|     3|   Yousif, Mr. Wazli|  male|30.079501879699244|    0|    0|         2647|   7.225|    U|       C|    Mr|\n",
      "|        712|       0|     1|  Klaber, Mr. Herman|  male|30.079501879699244|    0|    0|       113028|   26.55|    C|       S|    Mr|\n",
      "|        755|       1|     2|Herman, Mrs. Samu...|female|              48.0|    1|    2|       220845|    65.0|    U|       S|   Mrs|\n",
      "|        883|       0|     3|Dahlberg, Miss. G...|female|              22.0|    0|    0|         7552| 10.5167|    U|       S|  Miss|\n",
      "|         26|       1|     3|Asplund, Mrs. Car...|female|              38.0|    1|    5|       347077| 31.3875|    U|       S|   Mrs|\n",
      "|         36|       0|     3|Somerton, Mr. Fra...|  male|              30.0|    0|    0|   A.5. 18509|    8.05|    U|       S|    Mr|\n",
      "|         86|       0|     3|Risien, Mr. Samue...|  male|30.079501879699244|    0|    0|       364498|    14.5|    U|       S|    Mr|\n",
      "|        102|       1|     3|  Ohman, Miss. Velin|female|              22.0|    0|    0|       347085|   7.775|    U|       S|  Miss|\n",
      "|        201|       1|     3|\"O'Leary, Miss. H...|female|30.079501879699244|    0|    0|       330919|  7.8292|    U|       Q|  Miss|\n",
      "|        278|       1|     1|Allen, Miss. Elis...|female|              29.0|    0|    0|        24160|211.3375|    B|       S|  Miss|\n",
      "|        573|       1|     1|\"Flynn, Mr. John ...|  male|              36.0|    0|    0|     PC 17474| 26.3875|    E|       S|    Mr|\n",
      "|        685|       0|     2|Brown, Mr. Thomas...|  male|              60.0|    1|    1|        29750|    39.0|    U|       S|    Mr|\n",
      "|        693|       1|     3|        Lam, Mr. Ali|  male|30.079501879699244|    0|    0|         1601| 56.4958|    U|       S|    Mr|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|               2.0|    4|    1|       382652|  29.125|    U|       Q|Master|\n",
      "|        129|       1|     3|   Peter, Miss. Anna|female|30.079501879699244|    1|    1|         2668| 22.3583|    F|       C|  Miss|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+-------------+--------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train,test=combined.randomSplit([.8,.2],seed=0)\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "8C11xf1iAzKp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex', 'Ticket', 'Cabin', 'Embarked', 'Title']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricalCols = [field for (field, dataType) in train.dtypes\n",
    "                   if dataType == \"string\"]\n",
    "categoricalCols.remove('Name')\n",
    "# categoricalCols.remove('Title')\n",
    "categoricalCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex_Index', 'Ticket_Index', 'Cabin_Index', 'Embarked_Index', 'Title_Index']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexOutputCols = [x + \"_Index\" for x in categoricalCols]\n",
    "indexOutputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex_OHE', 'Ticket_OHE', 'Cabin_OHE', 'Embarked_OHE', 'Title_OHE']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oheOutputCols = [x + \"_OHE\" for x in categoricalCols]\n",
    "oheOutputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCols=categoricalCols,\n",
    "                             outputCols=indexOutputCols,\n",
    "                             handleInvalid='skip')\n",
    "oheEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
    "                          outputCols=oheOutputCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericCols = [field for (field,dataType) in train.dtypes\n",
    "              if ((dataType=='double')or (dataType=='int')& (field!='Survived'))]\n",
    "numericCols.remove('PassengerId')\n",
    "numericCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=oheOutputCols+numericCols,outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJQvmFai72O7"
   },
   "source": [
    "**Build RandomForestClassifier model and use pipeline to fit and transform then display \"prediction, Survived, features\" columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "MzIDSJzgA035"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "random_forest= RandomForestClassifier(featuresCol='features', labelCol='Survived', predictionCol='prediction', maxDepth=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Rl0UAKCaBDO-"
   },
   "outputs": [],
   "source": [
    "pipeline =Pipeline(stages = [stringIndexer,oheEncoder,vecAssembler,random_forest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Model=pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF = Model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSXEI8-r8bKY"
   },
   "source": [
    "**Use MulticlassClassificationEvaluator and set the \"labelCol\" to \"Survived\",  \"predictionCol\" to \"prediction\", \"metricName\" to \"accuracy\"** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "MClassC = MulticlassClassificationEvaluator(predictionCol='prediction',\n",
    "                                        labelCol='Survived',\n",
    "                                        metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.838150289017341"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = MClassC.evaluate(predDF)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO6_R1zJ9R1R"
   },
   "source": [
    "**When you are finished send the project via Google classroom**\n",
    "**Please let me know if you have any questions.**\n",
    "* nabieh.mostafa@yahoo.com\n",
    "* +201015197566 (Whatsapp)\n",
    "\n",
    "**Don't Hate me, I push you to learn**\n",
    "\n",
    "**I will help you to become an awesome data engineer.**\n",
    "\n",
    "**Why did I say that \"Data Engineer\"?**\n",
    "\n",
    "**Tricky question, but an optional question, if you would like to know the answer, ask me.**\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practical_work.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
